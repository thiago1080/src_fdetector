{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feriados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Janeiro\n",
    "01\tTER\tAno-Novo\n",
    "Abril\n",
    "19\tSEX\tSexta-feira Santa\n",
    "21\tDOM\tTiradentes\n",
    "21\tDOM\tPáscoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollydays=['2018-12-25', '2018-12-31','2019-01-01', '2019-03-04','2019-03-05','2019-03-06']\n",
    "for i in ['01','19','21']:\n",
    "    hollydays.append('2019-04-'+i)\n",
    "#hollydays = [pd.Timestamp(i) for i in hollydays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollydays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dates(df, dates, inplace=False):\n",
    "    \"\"\"\n",
    "        inputs:\n",
    "            df -> a dataframe indexed by dates\n",
    "            dates -> a list of str '%YYYY-MM-DD' dates\n",
    "            inplace -> similar to pd.drop inplace parameter\n",
    "        returns:\n",
    "            df where dates are dropped if inplace is False\n",
    "            None if inplace is True (similar to pd.drop)\n",
    "    \"\"\"\n",
    "    to_drop_dates = list()\n",
    "    for d in dates:\n",
    "        to_drop_dates = to_drop_dates + list(df[d].index)\n",
    "    dfo = df.drop(to_drop_dates,axis=0, inplace=inplace)\n",
    "    return dfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "processados = pickle.load(open('../pickles/all/processados.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erros = pickle.load(open('../pickles/all/erros.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from genData import load_model\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from genData import load_model\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from importlib import reload\n",
    "import mainlib\n",
    "reload(mainlib)\n",
    "import A_base as ab\n",
    "reload(ab)\n",
    "from  mainlib import fasorial, lista, sdict, mm, mm_sep\n",
    "\n",
    "\n",
    "import collections\n",
    "import of_proc\n",
    "reload(of_proc)\n",
    "from of_proc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(path = '../info/info.json'):\n",
    "    global PATH, OUTPUT_PATH, PROCESSED_PATH, PERFIS_PATH, HORARIOS_PATH, PATH_MM, PATH_FAS, \\\n",
    "    DEG, MOR, PER, FAS, OUTPUT_HEADER,FAS_CONCAT, MM_CONCAT, PICKLES_CONCAT, OUT_INDEX\n",
    "    with open(path) as f:\n",
    "        info = json.load(f)\n",
    "        PATH = info['paths']['fasoriais']['input']\n",
    "        OUTPUT_PATH = info['paths']['fasoriais']['output']\n",
    "        PROCESSED_PATH = info['paths']['fasoriais']['processed']\n",
    "        PERFIS_PATH = info['paths']['perfis']['perfis']\n",
    "        HORARIOS_PATH = info['paths']['perfis']['horarios']\n",
    "        PATH_MM = info['paths']['mm']['input']\n",
    "        PATH_FAS = info['paths']['fasoriais']['input']\n",
    "        DEG = info['paths']['nn_models']['degrau']\n",
    "        MOR = info['paths']['nn_models']['morro']\n",
    "        PER = info['paths']['nn_models']['perfil']\n",
    "        FAS = info['paths']['nn_models']['fasorial']\n",
    "        FAS_CONCAT =  info['paths']['concat']['fas']\n",
    "        MM_CONCAT =  info['paths']['concat']['mm'] \n",
    "        PICKLES_CONCAT=  info['paths']['concat']['pickles']        \n",
    "        OUTPUT_HEADER = info['output']['header']\n",
    "        OUT_INDEX = info['output']['header']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_CONCAT = '../outputs/concat/'\n",
    "OUT = '../outputs/all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preguiça -- arrumar\n",
    "out_index = OUT_INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar modelos neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleções principais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global LISTA_CAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global PERFIL, DEGRAU, MORRO, NN_FAS\n",
    "PERFIL, DEGRAU, MORRO, NN_FAS = load_models(PER, DEG, MOR, FAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global files_fas, files_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfis e horários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global HORARIOS, PERFIS, ATIVS, DPERFIS, DPERFIS_NORMAL, DPERFIS_TROCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estruturas auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global dim, dmi, df_fas, dfiles_mm, dfiles_fas_troca, dfiles_mm_troca, dfiles_fas_normal, dfiles_mm_normal\n",
    "global o_i_normal, o_i_troca, o_instas, list_i_normal, list_i_troca, list_intas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de medidores e lista por horários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTA_CAD = get_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORARIOS, PERFIS, ATIVS = get_horario_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionários e listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim, dmi = dicts(LISTA_CAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gls i_normal -> instalações normal\n",
    "# i_troca -> instalações com troca\n",
    "#o_i_normal -> ordenado instalações normal\n",
    "o_i_normal = collections.OrderedDict(sorted(LISTA_CAD.get_users(index = 'instalacao', troca=0,tipo='dictionary').items()))\n",
    "o_i_troca = collections.OrderedDict(sorted(LISTA_CAD.get_users(index = 'instalacao', troca=1,tipo='dictionary').items()))\n",
    "o_instas =  collections.OrderedDict(sorted({**o_i_normal, **o_i_troca}.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dicionário com os horário de funcionamento de cada cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPERFIS = sdict()\n",
    "for i in PERFIS.index:\n",
    "    j = PERFIS.loc[i,'Ramo de Atividade']\n",
    "    if HORARIOS.index.contains(j):\n",
    "        DPERFIS[i] = list(HORARIOS.loc[j,:])\n",
    "    else:\n",
    "        DPERFIS[i] = list(HORARIOS.iloc[0,:])\n",
    "\n",
    "DPERFIS_NORMAL={}\n",
    "for i in DPERFIS:\n",
    "    if i in o_i_normal:\n",
    "        DPERFIS_NORMAL[i] = o_i_normal[i]\n",
    "\n",
    "DPERFIS_TROCA={}\n",
    "for i in DPERFIS:\n",
    "    if i in o_i_troca:\n",
    "        DPERFIS_TROCA[i] = o_i_troca[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_fas, nf_fas=get_files_3(list(o_i_normal.keys()), dim,  PATH_FAS)\n",
    "dfiles_mm, nf_mm = get_files_3(list(o_i_normal.keys()),dim , PATH_MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_fas2 = deslistar(dfiles_fas)\n",
    "dfiles_mm2 = deslistar(dfiles_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_fas_concat, nf_fas_concat = get_files_2( list(o_i_troca.keys()), FAS_CONCAT)\n",
    "dfiles_mm_concat, nf_mm_concat = get_files_2( list(o_i_troca.keys()), MM_CONCAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_fas_concat = get_files_troca(dfiles_fas_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_mm_concat= get_files_troca(dfiles_mm_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf_concat = collections.OrderedDict(sorted(dfiles_fas_concat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odmm_concat = collections.OrderedDict(sorted(dfiles_mm_concat.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nova função de corrente zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_corrent_zero(grid):\n",
    "    pAmp = 20\n",
    "    relacao = 400/5\n",
    "    rdias = 0\n",
    "    rminutos = 0\n",
    "    severidade_regra = 0 #certeza de que nao tem nada errado\n",
    "    cdata = -1\n",
    "    \n",
    "    corrente_referencia = pAmp/relacao\n",
    "    rise = {}\n",
    "    rise['IA'] = (grid['IA'] >= corrente_referencia/3).any()\n",
    "    rise['IB'] = (grid['IB'] >= corrente_referencia/3).any()\n",
    "    rise['IC'] = (grid['IC'] >= corrente_referencia/3).any()\n",
    "\n",
    "#     print(\"Corrente de referencia:\", corrente_referencia)\n",
    "#     print(\"iA tem valores maiores que referencia/3: \", iA_levanta)\n",
    "#     print(\"iB tem valores maiores que referencia/3: \", iB_levanta)\n",
    "#     print(\"iC tem valores maiores que referencia/3: \", iC_levanta)\n",
    "\n",
    "    for index, row in grid.iterrows():\n",
    "        data = index.date()\n",
    "        datastr = index.strftime('%Y-%m-%d')\n",
    "        hora = index.time().hour\n",
    "        correntes={}\n",
    "        correntes['IA'] = float(row['IA'])*relacao\n",
    "        correntes['IB'] = float(row['IB'])*relacao\n",
    "        correntes['IC'] = float(row['IC'])*relacao\n",
    "        zeros = {'IA':0, 'IB':0, 'IC':0}\n",
    "        for i in ['IA', 'IB', 'IC']:\n",
    "            if (cdata == -1 or cdata != data):\n",
    "                #feriado = verificaFeriado(datastr, feriados)\n",
    "                #print(\"data: \", datastr, feriado)\n",
    "                if (cdata != -1):\n",
    "                    ocorrencias = (horas*4)*0.7 #70%do tempo\n",
    "                    #print(cdata,\"Ref Ocorrencias:\",ocorrencias,\"IA\",zeroiA,naozeroiA,\"IB\",zeroiB,naozeroiB,\"IC\",zeroiC,naozeroiC)\n",
    "                    #print(zeros[i])\n",
    "                    #continue\n",
    "                    if (zeros[i] >= ocorrencias): # and naozeroiA == 0):\n",
    "                        rdias +=1\n",
    "                        rminutos +=(zeros[i]*15)                  \n",
    "                #novo dia, começa a contar novamente\n",
    "                cdata = data\n",
    "                for i in correntes:\n",
    "                    correntes[i]=0\n",
    "                for i in zeros:\n",
    "                    zeros[i] = 0\n",
    "\n",
    "            horas= int(grid[datastr][i].resample('H').count().resample('D').count())\n",
    "            #hf,horas = horarioFuncionamento(hora, dia, semanai, semanaf, sabadoi, sabadof, domingoi, domingof)\n",
    "            #print(hf,cdata,hora,dia,iA,iB,iC)\n",
    "            if (correntes[i] == 0):\n",
    "                severidade_regra = 1\n",
    "                if (correntes['IA']+correntes['IB']+correntes['IC'] >= pAmp):\n",
    "                    #condição C = corrente zero e a soma das outras duas é maior ou igual a pAmp\n",
    "                    zeros[i] +=1\n",
    "                elif (not rise[i]):\n",
    "                    #condição A = corrente zero na fase A sendo que a fase A nunca ultrapassa 1/3 de pAmp\n",
    "                    zeros[i] +=1\n",
    "\n",
    "    #so para ajustar severidade_regra\n",
    "    if (rdias >= 10): # nao importa rminutos\n",
    "        severidade_regra = 2\n",
    "        \n",
    "    return rdias, rminutos, severidade_regra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:08:36.845424Z",
     "start_time": "2019-07-15T14:08:32.454860Z"
    }
   },
   "outputs": [],
   "source": [
    "#Nova implementação para contabilização de corrente zero\n",
    "#Novidades:\n",
    "# a) Lista de feriados\n",
    "# b) Regra de contabilização nao se restringe à corrente ser zero apenas dentro do horário de funcionamento e do feriado\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "from dateutil import parser\n",
    "\n",
    "# def parseDate(strdate):\n",
    "#     #format ddmmyyyyhhMMss\n",
    "#     try:\n",
    "#         result = parser.parse(strdate[0:2]+\"/\"+strdate[3:5]+\"/\"+strdate[6:10]+\" \"+strdate[11:13]+\":\"+strdate[14:16]+\":00\", dayfirst=True)\n",
    "#     except ValueError:\n",
    "#         #print (strdate)\n",
    "#         result = parser.parse(\"01/01/1980 00:00:00\", dayfirst=True)\n",
    "#     return result\n",
    "        \n",
    "def horarioFuncionamento(hora, dia, semanai=8, semanaf=18, sabadoi=8, sabadof=18, domingoi=8, domingof=18):\n",
    "    # veja que estou tratando String e tirei as acentuações do arquivo CSV\n",
    "    # se voce tiver jeito melhor de fazer pode mudar\n",
    "    if (dia == \"Sabado\"):\n",
    "        horas = sabadof - sabadoi\n",
    "        return (hora >= sabadoi and hora < sabadof), horas\n",
    "    if (dia == \"Domingo\"):\n",
    "        horas = domingof - domingoi\n",
    "        return (hora >= domingoi and hora < domingof), horas\n",
    "    else:\n",
    "        horas = semanaf - semanai\n",
    "        return (hora >= semanai and hora < semanaf), horas\n",
    "    \n",
    "def verificaFeriado(datastr, feriados):\n",
    "    return (feriados['Feriados'] == datastr).any()\n",
    "    \n",
    "def NEWcorrenteZero(grid, feriados, pAmp, relacao, semanai=8, semanaf=18, sabadoi=8, sabadof=18, domingoi=8, domingof=18):\n",
    "    rdias = 0\n",
    "    rminutos = 0\n",
    "    severidade_regra = 0 #certeza de que nao tem nada errado\n",
    "    cdata = -1\n",
    "    \n",
    "    corrente_referencia = pAmp/relacao\n",
    "    IA_levanta = (grid['IA'] >= corrente_referencia/3).any()\n",
    "    IB_levanta = (grid['IB'] >= corrente_referencia/3).any()\n",
    "    IC_levanta = (grid['IC'] >= corrente_referencia/3).any()\n",
    "    za, zb, zc = [], [], []\n",
    "    print(\"Corrente de referencia:\", corrente_referencia)\n",
    "    print(\"IA tem valores maiores que referencia/3: \", IA_levanta)\n",
    "    print(\"IB tem valores maiores que referencia/3: \", IB_levanta)\n",
    "    print(\"IC tem valores maiores que referencia/3: \", IC_levanta)\n",
    "    for index, row in grid.iterrows():\n",
    "        datetime = parseDate(row['data'])\n",
    "        data = datetime.date()\n",
    "        datastr = datetime.strftime(\"%d/%m/%Y\")\n",
    "        hora = datetime.time().hour\n",
    "        dia = row['Dia']\n",
    "        IA = float(row['IA'])*relacao\n",
    "        IB = float(row['IB'])*relacao\n",
    "        IC = float(row['IC'])*relacao\n",
    "        naozeroIA, naozeroIB, naozeroIC = 0,0,0\n",
    "        if (cdata == -1 or cdata != data):\n",
    "            feriado = verificaFeriado(datastr, feriados)\n",
    "            #print(\"data: \", datastr, feriado)\n",
    "            if (cdata != -1):\n",
    "                ocorrencias = (horas*4)*0.7 #70%do tempo\n",
    "                print(cdata,\"Ref Ocorrencias:\",ocorrencias,\"IA\",zeroIA,\"IB\",zeroIB,\"IC\",zeroIC)\n",
    "                za.append(zeroIA)\n",
    "                zb.append(zeroIB)\n",
    "                zc.append(zeroIC)\n",
    "                if (zeroIA >= ocorrencias): # and naozeroIA == 0):\n",
    "                    rdias +=1\n",
    "                    rminutos +=(zeroIA*15)\n",
    "                else:\n",
    "                    if (zeroIB >= ocorrencias): # and naozeroIB == 0):\n",
    "                        rdias +=1\n",
    "                        rminutos +=(zeroIB*15)\n",
    "                    else:\n",
    "                        if (zeroIC >= ocorrencias): # and naozeroIC == 0):\n",
    "                            rdias +=1\n",
    "                            rminutos +=(zeroIC*15)\n",
    "            #novo dia, começa a contar novamente\n",
    "            cdata = data\n",
    "            zeroIA, zeroIB, zeroIC = 0,0,0\n",
    "            naozeroIA, naozeroIB, naozeroIC = 0,0,0\n",
    "                   \n",
    "        hf,horas = horarioFuncionamento(hora, dia, semanai, semanaf, sabadoi, sabadof, domingoi, domingof)\n",
    "        #print(hf,cdata,hora,dia,IA,IB,IC)\n",
    "        \n",
    "        if (hf and not feriado):\n",
    "            if (IA == 0):\n",
    "                severidade_regra = 1\n",
    "                if (IA+IB+IC >= pAmp):\n",
    "                    #condição C = corrente zero e a soma das outras duas é maior ou igual a pAmp\n",
    "                    zeroIA +=1\n",
    "                else:\n",
    "                    if (not IA_levanta):\n",
    "                        #condição A = corrente zero na fase A sendo que a fase A nunca ultrapassa 1/3 de pAmp\n",
    "                        zeroIA +=1\n",
    "            else:\n",
    "                naozeroIA +=1\n",
    "            if (IB == 0):\n",
    "                severidade_regra = 1\n",
    "                if (IA+IB+IC >= pAmp):\n",
    "                    #condição C = corrente zero e a soma das outras duas é maior ou igual a pAmp\n",
    "                    zeroIB +=1\n",
    "                else:\n",
    "                    if (not IB_levanta):\n",
    "                        #condição A = corrente zero na fase A sendo que a fase A nunca ultrapassa 1/3 de pAmp\n",
    "                        zeroIB +=1\n",
    "            else:\n",
    "                naozeroIB +=1\n",
    "            if (IC == 0):\n",
    "                severidade_regra = 1\n",
    "                if (IA+IB+IC >= pAmp):\n",
    "                    #condição C = corrente zero e a soma das outras duas é maior ou igual a pAmp\n",
    "                    zeroIC +=1\n",
    "                else:\n",
    "                    if (not IC_levanta):\n",
    "                        #condição A = corrente zero na fase A sendo que a fase A nunca ultrapassa 1/3 de pAmp\n",
    "                        zeroIC +=1\n",
    "            else:\n",
    "                naozeroIC +=1\n",
    "\n",
    "    #so para ajustar severidade_regra\n",
    "    if (rdias >= 10): # nao importa rminutos\n",
    "        severidade_regra = 2\n",
    "        \n",
    "    return rdias, rminutos, severidade_regra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T14:08:36.845424Z",
     "start_time": "2019-07-15T14:08:32.454860Z"
    }
   },
   "outputs": [],
   "source": [
    "#teste\n",
    "file = 'from_w/BTI410315485-fasor_08552562_20190711_153409.csv'\n",
    "grid=pd.read_csv(file,delimiter=';').astype('object')\n",
    "file = 'from_w/feriados.csv'\n",
    "feriados=pd.read_csv(file,delimiter=';').astype('object')\n",
    "pAmp = 20\n",
    "relacao = 400/5 # Observacao: cliente BT2A a relação é 1/1\n",
    "\n",
    "#dias, minutos, severidade_regra = NEWcorrenteZero(grid, feriados, pAmp, relacao, 8, 18, 8, 18, 8, 18)\n",
    "#print (\"Dias com corrente zero em horario de funcionamento:\",dias, \" --- Minutos:\", minutos, \" (\", severidade_regra, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDate(strdate):\n",
    "    #format ddmmyyyyhhMMss\n",
    "    try:\n",
    "        result = parser.parse(strdate[0:2]+\"/\"+strdate[3:5]+\"/\"+strdate[6:10]+\" \"+strdate[11:13]+\":\"+strdate[14:16]+\":00\", dayfirst=True)\n",
    "    except ValueError:\n",
    "        #print (strdate)\n",
    "        result = parser.parse(\"01/01/1980 00:00:00\", dayfirst=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrente zero\n",
    "##### Comparar resultado da nova função de corrente zero acima e a que fiz em pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mainlib\n",
    "reload(mainlib)\n",
    "from mainlib import fasorial, infos\n",
    "\n",
    "hours = infos().hours\n",
    "hollydays = infos().hollydays\n",
    "ddays = infos().ddays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_months(fas,less=False):\n",
    "    for y in fas.months:\n",
    "        for m in fas.months[y]:\n",
    "            if less:\n",
    "                fas.months[y][m].proc_fasorial_less()\n",
    "            else:\n",
    "                fas.months[y][m].proc_fasorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fas(ex1, proc=True, **kwargs):\n",
    "    if ex1 in dfiles_fas_concat.keys():\n",
    "        print('troca')\n",
    "        file1 = dfiles_fas_concat[ex1]\n",
    "        ddays=o_i_troca[ex1]\n",
    "        path = FAS_CONCAT\n",
    "        f1 = fasorial(name=ex1)\n",
    "        f1.read_fasorial(os.path.join(path,file1), dtype=None)\n",
    "    elif ex1 in dfiles_fas.keys():\n",
    "        print('normal')\n",
    "        file1 = dfiles_fas[ex1] \n",
    "        ddays=o_i_normal[ex1]\n",
    "        path = PATH_FAS       \n",
    "        f1 = fasorial(name=ex1)\n",
    "        f1.read_fasorial(os.path.join(path,file1[0]), dtype=None)\n",
    "    \n",
    "    \n",
    "    f1.split_months(ddays=ddays)\n",
    "    if proc:\n",
    "        proc_months(f1, **kwargs)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc2m(f1, proc=False):\n",
    "    ld = sdict()\n",
    "    for y in f1.months:\n",
    "        for m in f1.months[y]:\n",
    "            month = f1.months[y][m].df.copy()\n",
    "            if proc:\n",
    "                month = proc1m(month)\n",
    "            ld[m] = month\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc1m(m):\n",
    "    m.reset_index(inplace=True, drop=False)\n",
    "    m['Dia']= m['data'].apply(lambda x: x.weekday()).map(said)\n",
    "    m['data'] =pd.to_datetime(m['data'])\n",
    "    m['data']= m['data'].apply(lambda x: x.strftime('%d/%m/%Y %H:%M'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias = {\n",
    "    \"Segunda\":0,\n",
    "    \"Terca\":1,\n",
    "    \"Quarta\":2,\n",
    "    \"Quinta\":3,\n",
    "    \"Sexta\":4,\n",
    "    \"Sabado\":5,\n",
    "    \"Domingo\":6\n",
    "    \n",
    "}\n",
    "said = {v:k for k,v in dias.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = ['8:00', '18:00', '8:00', '18:00', '8:00', '18:00', '0:00', '0:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-> segunda\n",
    "#6 -> domingo\n",
    "#7 feriado\n",
    "hours2 = {\n",
    "    0:('8:00', '18:00'),\n",
    "    1:('8:00', '18:00'),\n",
    "    2:('8:00', '18:00'),\n",
    "    3:('8:00', '18:00'),\n",
    "    4:('8:00', '18:00'),\n",
    "    5:('8:00', '18:00'),\n",
    "    6:('8:00', '18:00'),\n",
    "    7:('0:00', '0:00'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hollydays = [\n",
    "'2019-03-02',\n",
    "'2019-03-03',\n",
    " '2019-03-04',\n",
    " '2019-03-05',\n",
    " '2019-03-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário único para todos os caminhos de arquivos\n",
    "ddirs={}\n",
    "for u,v in dfiles_fas2.items():\n",
    "    ddirs[u] = os.path.join(PATH_FAS,v)\n",
    "for u,v in dfiles_fas_concat.items():\n",
    "    if u in ddirs:\n",
    "        print('Warning. Instalacao repetida')\n",
    "    ddirs[u] = os.path.join(FAS_CONCAT, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasorial(path,insta='not_found',iddays=default_ddays(),**kwargs):\n",
    "    f = fasorial(name=insta, ddays = iddays)\n",
    "    f.read_fasorial(path,**kwargs)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Criar um fasorial simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mainlib\n",
    "reload(mainlib)\n",
    "from mainlib import fasorial, mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1='BTI413195196'\n",
    "i4 = 'BTI430044836'\n",
    "f = get_fasorial(ddirs[i4], insta=i4, dtype=None)\n",
    "df = f.df['2019-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check_fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,i = fasorial().check_df(pd.DataFrame({1:{2:3,4:5}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df,i = f.check_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop_fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.drop_fas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### string_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=f.string_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = f.count_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i4 = 'BTI430044836'\n",
    "f = get_fasorial(ddirs[i4], insta=i4, dtype=None)\n",
    "df = f.df['2019-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=f.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.applymap(f.proc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.df['PB'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['PB'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i4 = 'BTI430044836'\n",
    "f = get_fasorial(ddirs[i4], insta=i4, dtype=None)\n",
    "df = f.df['2019-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.index.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.remove_dup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(f.shape_dup[0] == f.df.shape[0] + f.duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "####  BTI413195196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1='BTI413195196'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1_bigger = build_fas(ex1, less=True)\n",
    "months_bigger = proc2m(f1_bigger)\n",
    "months_proc_bigger = proc2m(f1_bigger, proc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = build_fas(ex1)\n",
    "months = proc2m(f1)\n",
    "months_proc = proc2m(f1, proc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-999 na mm --> 'BTI410630442'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem de métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo = 'BT2A400029491'\n",
    "arquivo = dfiles_fas[exemplo][0]\n",
    "f = fasorial()\n",
    "f.read_fasorial(os.path.join(PATH_FAS, arquivo), sep=';', dtype= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(f.df)),f.df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- fasorial.remove_dup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dup(df):\n",
    "    c=0\n",
    "    c1=0\n",
    "    for i in df.index:\n",
    "        if c == i :\n",
    "            c1 +=1\n",
    "        c=i\n",
    "    return c1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dup_2(df):\n",
    "    return df.index.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_dup(f.df), check_dup_2(f.df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(f.df) - len(f.remove_dup(df = f.df.copy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.remove_dup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-  fasorial.drop_hollydays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-  fasorial.split_months\n",
    "##### Pega 30 dias antes da data de leitura, exclusive a última"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {'Janeiro':1, 'Fevereiro':2, 'Março':3, 'Abril':4, 'Dezembro':12}\n",
    "months2 = dict([[v,k] for k,v in months.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddays = default_ddays()\n",
    "ddays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(f.df[ddays[12] - pd.Timedelta(days=30):ddays[12]]),\n",
    "    len(f.df[ddays[1] - pd.Timedelta(days=30):ddays[1]]),\n",
    "    len(f.df[ddays[2] - pd.Timedelta(days=30):ddays[2]]),\n",
    "    len(f.df[ddays[3] - pd.Timedelta(days=30):ddays[3]]),\n",
    "    len(f.df[ddays[4] - pd.Timedelta(days=30):ddays[4]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.split_months(ddays=ddays)\n",
    "for y in f.months:\n",
    "    for m in f.months[y]:\n",
    "        print(len(f.months[y][m].df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in f.months:\n",
    "    for m in f.months[y]:\n",
    "        print(pd.Timestamp(f.months[y][m].df.index[0]).weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in f.months:\n",
    "    for m in f.months[y]:\n",
    "        print(months2[m])\n",
    "        print(f.months[y][m].df.resample('D').count().resample('M').count().iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-  fasorial.proc_fasorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mainlib\n",
    "\n",
    "reload(mainlib)\n",
    "\n",
    "from mainlib import fasorial\n",
    "\n",
    "#provisório\n",
    "exemplo = 'BT2A400029491'\n",
    "arquivo = dfiles_fas[exemplo][0]\n",
    "f = fasorial()\n",
    "f.read_fasorial(os.path.join(PATH_FAS, arquivo), sep=';', dtype= None)\n",
    "f.remove_dup()\n",
    "f.split_months(ddays = default_ddays())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan = copy.deepcopy(f.months[2019][1])\n",
    "\n",
    "daterange(jan.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30*24*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.proc_fasorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jan.df.shape[0] == 30*24*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-  fasorial.feat_eng_fasorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.feat_eng_fasorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.feat_eng_fasorial??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tension_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.tension_angles??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['AVA','AVB', 'aab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['AVA','AVC', 'aac']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['AVB','AVC', 'abc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_of_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.feat_eng_fasorial??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['VA', 'VB', 'VC', 'minV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['IA', 'IB', 'IC','minA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['PA', 'PB', 'PC','minP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### angle_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.angle_check??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['aab','abc','aac','angcheck']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df[['aab','abc','aac','angcheck']][jan.df['angcheck']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### call_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.call_pot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.potNegativa??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize\n",
    "##### <li> day_check <li> quantity_check <li> day_check_bool <li> quantity_check_bool <li> ult_corrente_zero <li> sunlight <li> cut_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.deepcopy(jan.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### day_check\n",
    "##### <li> Dúvida. Atualmente ativa com apenas uma leitura no dia. Isso está certo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.day_check??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['minV']<0.0001]['minV'].resample('D').min().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### quantity_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.quantity_check??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.quantity_check('minV',threshold=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['minV']<0.0001]['minV'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "day_check_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.day_check_bool??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.df.iloc[-600:]['angcheck'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.day_check_bool(jan.df.iloc[-600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterange(jan.df.iloc[-600:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantity_check_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.quantity_check_bool??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['aab','abc','aac']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['angcheck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.cut_hours??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours2 = ['6:00', '7:00', '6:00', '7:00', '6:00', '7:00', '6:00', '7:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterange(jan.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.cut_hours(hours2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sun_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.sunlight??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan.sunlight()['2019-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
