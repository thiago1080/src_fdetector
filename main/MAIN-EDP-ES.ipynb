{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "sys.path.append(join(Path(os.getcwd()).parent, 'lib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.1.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections\n",
    "from importlib import reload\n",
    "from  mainlib import fasorial, lista, sdict, mm, mm_sep\n",
    "from unidecode import unidecode\n",
    "from of_proc import *\n",
    "from os.path import join\n",
    "from os import listdir as ld\n",
    "from unidecode import unidecode\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(path):\n",
    "    global PATH, OUTPUT_PATH, PROCESSED_PATH, PERFIS_PATH, HORARIOS_PATH, PATH_MM, PATH_FAS, \\\n",
    "    DEG, MOR, PER, FAS, OUTPUT_HEADER,FAS_CONCAT, MM_CONCAT, PICKLES_CONCAT, OUT_INDEX, COLS_LISTA, \\\n",
    "    OUT, DATA_DIR, LISTA_CAD_PATH, PROCESSADOS_PICKLE, ERROS_PICKLE, LOGS_DIR\n",
    "    with open(path) as f:\n",
    "        info = json.load(f)\n",
    "        PATH_FAS = info['paths']['fasoriais2']['input']\n",
    "        PERFIS_PATH = info['paths']['perfis']['perfis']\n",
    "        HORARIOS_PATH = info['paths']['perfis']['horarios']\n",
    "        PATH_MM = info['paths']['mm']['input']\n",
    "        DEG = info['paths']['nn_models']['degrau']\n",
    "        MOR = info['paths']['nn_models']['morro']\n",
    "        PER = info['paths']['nn_models']['perfil']\n",
    "        FAS = info['paths']['nn_models']['fasorial']\n",
    "        COLS_LISTA = info['lista2']['columns']  \n",
    "        OUTPUT_HEADER = info['output']['header']\n",
    "        OUT_INDEX = info['output']['header']\n",
    "        OUT = info['paths']['output']\n",
    "        DATA_DIR = info['paths']['base_dir']\n",
    "        LISTA_CAD_PATH = info['paths']['lista']\n",
    "        PROCESSADOS_PICKLE = info['paths']['processados']\n",
    "        ERROS_PICKLE = info['paths']['erros']\n",
    "        LOGS_DIR = info['paths']['logs']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = '../../info/info-EDP-ES.json'\n",
    "gd = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dk(d,k=0): return list(d.values())[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_info(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horario_info2(json_file):\n",
    "    with open(json_file) as jinfo:\n",
    "        info = json.load(jinfo)\n",
    "        HORARIOS_PATH = info['paths']['perfis']['horarios']\n",
    "        PERFIS_PATH = info['paths']['perfis']['perfis']\n",
    "        ATIV_PATH = info['paths']['perfis']['mapa']\n",
    "\n",
    "\n",
    "    perfis = pd.read_csv(PERFIS_PATH, sep = ';')\n",
    "    ativs = pd.read_csv(ATIV_PATH, sep = ';')\n",
    "\n",
    "    #perfis.columns = ['id', 'instalacao', 'cpf_cnpj', 'razao social', 'endereco_cadastro', 'ramo_de_atividade','None1', 'None2']\n",
    "    \n",
    "    dates = re.compile(\"[0-9]{2}:[0-9]{2}\")\n",
    "    dateparser = lambda x: pd.datetime.strptime(x, '%H:%M') if type(x) == str  and dates.match(x) else pd.NaT\n",
    "    cols = ['name','inicio_dia_util','fim_dia_util', 'inicio_sabado', 'fim_sabado', 'inicio_domingo', 'fim_domingo', 'inicio_feriado', 'fim_feriado']\n",
    "    horarios = pd.read_csv(HORARIOS_PATH, sep = ';',skipinitialspace=True, skiprows = 2, na_values = np.NaN, names = cols,\n",
    "                          date_parser = dateparser, parse_dates = [1,2,3,4,5,6,7,8])\n",
    "    \n",
    "    \n",
    "    horarios.set_index('name', inplace = True)\n",
    "    horarios.dropna(inplace=True)\n",
    "\n",
    "    perfis.set_index('instalacao', inplace=True)\n",
    "    perfis = (perfis.groupby(level=0).first())\n",
    "\n",
    "    \n",
    "    return horarios, perfis, ativs\n",
    "\n",
    "def get_files_4(nomes, dim,  CAMINHO):\n",
    "    not_found = []\n",
    "    dif = {}\n",
    "    for i in nomes:\n",
    "        if i in dim:\n",
    "            tmp_list = []\n",
    "            search = ab.search_list_2(str(i),os.listdir(CAMINHO))\n",
    "            if search:\n",
    "                dif[i] = search\n",
    "            else:\n",
    "                not_found.append(i)                \n",
    "    return dif, not_found\n",
    "\n",
    "#Criar dicionario de categorias\n",
    "def insta2horario(HORARIOS_PATH):\n",
    "    horarios = pd.read_csv(HORARIOS_PATH, sep=',')\n",
    "    horarios.drop(columns=horarios.columns[0],inplace=True)\n",
    "    horarios.columns = ['nome', 'cat', 'dias_uteis_i',\n",
    "           'dias_uteis_f', 'sabado_i', 'sabado_f', 'domingo_i',\n",
    "           'domingo_f', 'feriado_i', 'feriado_f']\n",
    "    horarios['nome'] = horarios['nome'].apply(unidecode)\n",
    "    dfcat = horarios.iloc[:,:2]\n",
    "    dfcat.set_index('nome',inplace=True)\n",
    "    scat = dfcat['cat']\n",
    "    dcat = scat.to_dict()\n",
    "    horarios.set_index('nome', inplace=True)\n",
    "    func = {k: [pd.Timestamp(v) for v in horarios.loc[k,'dias_uteis_i':'feriado_f']] for k in horarios.index}\n",
    "    return func\n",
    "\n",
    "def per2cluster(func, ATIV):\n",
    "    dfativ = pd.read_csv(ATIV, sep=';', names = ['ramo', 'perfil'])\n",
    "    dfativ=dfativ.applymap(unidecode)\n",
    "    dfativ.set_index('ramo', inplace=True)\n",
    "    a2p = dfativ.loc[:,'perfil'].T.to_dict()\n",
    "    a2p.pop('Ramo de Atividade')\n",
    "    p2a = dict((v,k) for k,v in a2p.items())\n",
    "    perfunc=PERFIS['ramo_de_atividade'].map(a2p).map(func)\n",
    "    return perfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global df_mm_new\n",
    "mmm = mm(json_file)\n",
    "df_mm_new = pd.read_csv(PATH_MM,date_parser = mmm.dateparser, index_col=[0], sep=';')\n",
    "dummy_mm = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar modelos neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleções principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global LISTA_CAD\n",
    "global PERFIL, DEGRAU, MORRO, NN_FAS\n",
    "global files_fas, files_mm\n",
    "global HORARIOS, PERFIS, ATIVS, DPERFIS, DPERFIS_NORMAL, DPERFIS_TROCA\n",
    "global dim, dmi, df_fas, dfiles_mm, dfiles_fas_troca, dfiles_mm_troca, dfiles_fas_normal, dfiles_mm_normal\n",
    "global o_i_normal, o_i_troca, o_instas, list_i_normal, list_i_troca, list_intas, gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "PERFIL, DEGRAU, MORRO, NN_FAS = load_models(PER, DEG, MOR, FAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTAF = pd.read_csv(LISTA_CAD_PATH, names = COLS_LISTA, header=0, sep=';',engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTAF['instalacao'] = pd.DataFrame(LISTAF['instalacao'].astype(int).apply(lambda x: '{0:0>10}'.format(x)))\n",
    "LISTAF['medidor'] = pd.DataFrame(LISTAF['medidor'].astype(int).apply(lambda x: '{0:0>8}'.format(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes = [\n",
    "'0000081002',\n",
    "'0000357754',\n",
    "'0000586609',\n",
    "'0001659074',\n",
    "'0009502437',\n",
    "'0160214293',\n",
    "'0160557791',\n",
    "'0160581342',\n",
    "'0160669410'   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTAF = LISTAF[LISTAF['instalacao'].isin(faltantes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc7 in position 15: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc7 in position 15: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2323316bd277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLISTA_CAD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLISTA_CAD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mLISTAF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mHORARIOS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERFIS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATIVS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_horario_info2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLISTA_CAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/code/ref_fdetector/src/lib/of_proc.py\u001b[0m in \u001b[0;36mget_list\u001b[0;34m(json_file, li)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0m_lista_cad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cliente'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instalacao'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'medidor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_inicio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_fim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lote'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ssn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dez'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jan'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'abr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'troca'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0m_lista_cad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_lista\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_lista_cad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/code/ref_fdetector/src/lib/mainlib.py\u001b[0m in \u001b[0;36mread_lista\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0m_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdateparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_rows\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc7 in position 15: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "LISTA_CAD = get_list(json_file)\n",
    "LISTA_CAD.df =  LISTAF\n",
    "HORARIOS, PERFIS, ATIVS = get_horario_info2(json_file)\n",
    "dim, dmi = dicts(LISTA_CAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estruturas auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LISTA_CAD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8759e5536aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo_i_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLISTA_CAD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmes_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtroca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mo_i_troca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLISTA_CAD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmes_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtroca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mo_instas\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mo_i_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mo_i_troca\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LISTA_CAD' is not defined"
     ]
    }
   ],
   "source": [
    "o_i_normal = collections.OrderedDict(sorted(LISTA_CAD.mes_days(troca=False).items()))\n",
    "o_i_troca = collections.OrderedDict(sorted(LISTA_CAD.mes_days(troca=True).items()))\n",
    "o_instas =  collections.OrderedDict(sorted({**o_i_normal, **o_i_troca}.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import A_base\n",
    "reload(A_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import A_base as ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiles_fas, nf_fas= get_files_4(list(o_instas.keys()), dim,  PATH_FAS)\n",
    "ddirs_fas = {k:join(PATH_FAS,v) for k,v in dfiles_fas.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista , perfis e horários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de instalacao para horario de funcionamento\n",
    "func =  insta2horario(HORARIOS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de perfis para clusters\n",
    "perfunc = per2cluster(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percats = PERFIS['cat'].fillna(value=0).apply(int).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " l___________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdump(o_instas, '../../pickles/o_instas.pkl')\n",
    "pdump(func, '../../pickles/func.pkl')\n",
    "pdump(perfunc, '../../pickles/perfunc.pkl')\n",
    "pdump(ddirs_fas, '../../pickles/ddirs_fas.pkl')\n",
    "pdump(dim, '../../pickles/dim.pkl')\n",
    "pdump(dmi, '../../pickles/dmi.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_hora = []\n",
    "err_msg = {}\n",
    "missing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSADOS_PICKLE,'rb') as p:\n",
    "    processados=pickle.load(p)\n",
    "with open(ERROS_PICKLE,'rb') as p:\n",
    "    erros = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open(os.path.join(LOGS_DIR,str(log_count)), 'at+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(string):\n",
    "    print(string)\n",
    "    log_file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dici2list(d_insta_to_days):\n",
    "    ddays={}\n",
    "    ddays[4],ddays[5],ddays[6],ddays[7] = d_insta_to_days[12], d_insta_to_days[1], d_insta_to_days[2], d_insta_to_days[3], d_insta_to_days[4]\n",
    "    return ddays\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn' . option None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PERFIS.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padrao = [pd.Timestamp('2019-09-20 00:00:00'),\n",
    " pd.Timestamp('2019-09-20 23:59:00'),\n",
    " pd.Timestamp('2019-09-20 00:00:00'),\n",
    " pd.Timestamp('2019-09-20 23:59:00'),\n",
    " pd.Timestamp('2019-09-20 00:00:00'),\n",
    " pd.Timestamp('2019-09-20 23:59:00'),\n",
    " pd.Timestamp('2019-09-20 00:00:00'),\n",
    " pd.Timestamp('2019-09-20 23:59:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopy2(d_insta_to_days, d_insta_to_files_fas, d_insta_to_files_mm,PATH_FAS, PATH_MM, output_dir,sepfas, sepmm, gd):\n",
    "    df_out = pd.DataFrame(index=OUT_INDEX)\n",
    "    global difas, dimm\n",
    "    global dfas, dmm,  dimm\n",
    "    difas, dimm = sdict(), sdict()\n",
    "    c = 0\n",
    "    c1 = 0\n",
    "    for instalacao in d_insta_to_days:\n",
    "        c1 = c1 + 1\n",
    "        if (instalacao  not in processados):\n",
    "            log(str(c)+'--'+'######## ' + instalacao + ' #########')\n",
    "            medidor = dim[instalacao][0] if type(dim[instalacao]) is list else dim[instalacao]\n",
    "            try:      \n",
    "                print('------ 0')\n",
    "                #ramo = percats[instalacao] if instalacao in percats else 0\n",
    "                ramo = 0\n",
    "                print('------ 1')\n",
    "                #hours = perfunc[instalacao] if instalacao in perfunc else padrao\n",
    "                hours = padrao\n",
    "                print('------ 2')\n",
    "                ddays = d_insta_to_days[instalacao] if instalacao in d_insta_to_days else default_ddays_2()\n",
    "                print('------ 3')\n",
    "                dfas = fasorial(json_file, name = instalacao, ddays=ddays)     \n",
    "                print('------ 4')\n",
    "                dfas.outputs['perfil'] = ramo\n",
    "                print('------ 5')\n",
    "                dfas.read_fasorial(d_insta_to_files_fas[instalacao], dtype=None, index_col=[5], sep = sepfas)\n",
    "                print('------ 6')\n",
    "                dmm = mm(json_file, name = instalacao, ddays = ddays, ramo=ramo)\n",
    "                print('------ 7')\n",
    "                if dim[instalacao] in df_mm_new.columns:\n",
    "                    dmm.df = pd.DataFrame(df_mm_new[dim[instalacao]])\n",
    "                else:\n",
    "                    dmm.df = pd.DataFrame(df_mm_new[str(int(dim[instalacao]))])                 \n",
    "\n",
    "                print('------ 8')\n",
    "                proc_fas(dfas,ddays, NN_FAS, json_file, hours = dfas.hours, gd=gd)\n",
    "                processa_mm(dmm, ddays, PERFIL, DEGRAU, MORRO, json_file)\n",
    "                print(d_insta_to_files_fas[instalacao])\n",
    "                print('################################################')\n",
    "                #Cria um dicionário de outputs por mês para o fasorial\n",
    "                for y in dfas.months:\n",
    "                    dfas.outputs[y] = {}\n",
    "                    for month  in dfas.months[y]:\n",
    "                        dfas.outputs[y][month] = dfas.months[y][month].outputs                \n",
    "                df_out = cat_out2(df_out, dmm.outputs, dfas.outputs, ddays,OUT_INDEX)\n",
    "\n",
    "                difas[instalacao] = dfas\n",
    "                dimm[instalacao] = dmm                \n",
    "                c = c+1                \n",
    "                #if c1 % 100 ==0 :  \n",
    "                if False:\n",
    "                    #return df_out, dfas, dmm\n",
    "                    log('Salvando csv!')\n",
    "                    df_out.T.to_csv(output_dir + 'e1_' +str(c1-100) + '_to_' + str(c1) +'.csv')                    \n",
    "                    pickle.dump(processados, open(PROCESSADOS_PICKLE,'wb'))\n",
    "                    pickle.dump(erros, open(ERROS_PICKLE,'wb'))                    \n",
    "                    df_out=pd.DataFrame()\n",
    "                processados.append(instalacao)\n",
    "            except Exception as e:\n",
    "                erros.append(instalacao)\n",
    "                err_msg[instalacao] = traceback.format_exc()\n",
    "                print('++++++Erro 2++++++++++ \\n'+ str(traceback.format_exc())+'\\n++++++++++++++++++++')\n",
    "    df_out.T.to_csv(output_dir + 'new.csv')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mainlib import mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processados, erros = [], []\n",
    "sepmm=','\n",
    "sepfas=';'\n",
    "m=loopy2(o_instas, ddirs_fas, dummy_mm, PATH_FAS, PATH_MM, OUT, sepfas, sepmm, gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substituir coluna \"Perfil cadastrado\" por texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=LISTA_CAD.df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra=PERFIS['ramo_de_atividade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dra=ra.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pd.read_csv('../../outputs/all/EDP-ES/new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o['Perfil cadastrado']=o['Nome'].map(dra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.to_csv('../../outputs/all/EDP-ES/new2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leituras faltando - Fasorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mainlib\n",
    "reload(mainlib)\n",
    "from mainlib import dframe\n",
    "\n",
    "dfr = dframe()\n",
    "data = dfr.data\n",
    "dp = dfr.dateparser\n",
    "\n",
    "ddirs_fas = pload('../pickles/ddirs_fas.pkl')\n",
    "\n",
    "emp = {}\n",
    "for n,(k,v) in enumerate(ddirs_fas.items()):\n",
    "    df = pd.read_csv(v,sep=';',date_parser = dp,parse_dates=[5],names=data['fasorial']['columns'])\n",
    "    emp[k]=df.set_index('data').iloc[:,0].resample('15min').first().isna().sum()\n",
    "    print(n,k,emp[k])\n",
    "\n",
    "demp=pd.DataFrame(index=emp.keys(), data=emp.values(),columns = ['Leituras faltantes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demp.to_csv('../outputs/fas_emp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leituras faltando - Fasorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = pd.read_csv(PATH_MM, parse_dates = [0],date_parser=dp, index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm[mm.index.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
